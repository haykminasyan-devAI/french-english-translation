# Project Structure

## Overview

Professional, production-ready organization for a neural machine translation project.

## Directory Structure

```
translation/
â”œâ”€â”€ README.md                       # Project overview and quick start
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ best_model*.pt                  # Symlinks to trained models
â”‚
â”œâ”€â”€ data/                           # All datasets
â”‚   â”œâ”€â”€ raw/                        # Original corpus
â”‚   â”‚   â””â”€â”€ giga-fren/             # 22M sentence pairs
â”‚   â”œâ”€â”€ processed/                  # Preprocessed data
â”‚   â”‚   â”œâ”€â”€ questions.csv          # 52K filtered questions
â”‚   â”‚   â”œâ”€â”€ vocab.pkl              # Vocabularies (word2idx, idx2word)
â”‚   â”‚   â””â”€â”€ embeddings.pkl         # Pre-trained fastText embeddings
â”‚   â””â”€â”€ giga-fren.tgz              # Downloaded archive
â”‚
â”œâ”€â”€ models/                         # Trained model checkpoints
â”‚   â”œâ”€â”€ model1/
â”‚   â”‚   â”œâ”€â”€ best_model1.pt         # Best Model 1 checkpoint
â”‚   â”‚   â””â”€â”€ model1_test_results.pkl
â”‚   â”œâ”€â”€ model2/
â”‚   â”‚   â””â”€â”€ best_model2.pt         # Best Model 2 checkpoint
â”‚   â””â”€â”€ model3/
â”‚       â””â”€â”€ best_model3.pt         # Best Model 3 checkpoint
â”‚
â”œâ”€â”€ scripts/                        # All executable scripts
â”‚   â”œâ”€â”€ train/                      # Training scripts
â”‚   â”‚   â”œâ”€â”€ train__model_1.py      # Model 1: Basic Seq2Seq
â”‚   â”‚   â”œâ”€â”€ train__model_2.py      # Model 2: + Bahdanau Attention
â”‚   â”‚   â””â”€â”€ train__model_3.py      # Model 3: Transformer
â”‚   â”œâ”€â”€ evaluate/                   # Evaluation & utilities
â”‚   â”‚   â”œâ”€â”€ evaluate_model1.py     # Model-specific evaluation
â”‚   â”‚   â”œâ”€â”€ evaluate_model2.py
â”‚   â”‚   â”œâ”€â”€ evaluate_model3.py
â”‚   â”‚   â”œâ”€â”€ evaluate_all_models.py # Compare all models
â”‚   â”‚   â”œâ”€â”€ evaluate_with_metrics.py  # Detailed metrics
â”‚   â”‚   â”œâ”€â”€ interactive_translator.py # Interactive CLI tool
â”‚   â”‚   â”œâ”€â”€ show_translations.py   # Quick translation viewer
â”‚   â”‚   â”œâ”€â”€ compare_all_translations.py
â”‚   â”‚   â””â”€â”€ visualize_results.py   # Plot training curves
â”‚   â””â”€â”€ slurm/                      # HPC job scripts
â”‚       â”œâ”€â”€ run_training_model1.sh
â”‚       â”œâ”€â”€ run_training_model2.sh
â”‚       â””â”€â”€ run_training_model3.sh
â”‚
â”œâ”€â”€ logs/                           # Training logs
â”‚   â”œâ”€â”€ model1_*.log
â”‚   â”œâ”€â”€ model2_*.log
â”‚   â””â”€â”€ model3_*.log
â”‚
â”œâ”€â”€ visualizations/                 # Generated plots
â”‚   â”œâ”€â”€ training_comparison.png    # 4-panel comparison
â”‚   â”œâ”€â”€ Model_1_Basic_Seq2Seq_training.png
â”‚   â”œâ”€â”€ Model_2_+_Attention_training.png
â”‚   â””â”€â”€ Model_3_Transformer_training.png
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â””â”€â”€ fr2eng.ipynb               # Data exploration & preprocessing
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ MODELS_SUMMARY.md          # Technical model details
â”‚   â”œâ”€â”€ FINAL_RESULTS.md           # Results analysis
â”‚   â””â”€â”€ PROJECT_SUMMARY.md         # Complete project overview
â”‚
â”œâ”€â”€ cc.fr.300.vec                   # Pre-trained French embeddings
â”œâ”€â”€ cc.en.300.vec                   # Pre-trained English embeddings
â””â”€â”€ venv/                           # Virtual environment
```

## ðŸŽ¯ Design Principles

1. **Separation of Concerns**: Code, data, models, docs in separate directories
2. **Clear Naming**: Descriptive folder and file names
3. **Hierarchical**: Logical grouping (scripts â†’ train/evaluate/slurm)
4. **Accessibility**: Symlinks for backward compatibility
5. **Scalability**: Easy to add new models or experiments

## ðŸ“¦ Key Directories

### `/data`
- **raw/**: Original, unmodified datasets
- **processed/**: Cleaned, filtered, ready-to-use data

### `/models`
- **model1/, model2/, model3/**: Separate checkpoints per model
- Prevents accidental overwrites
- Clear versioning

### `/scripts`
- **train/**: All training code
- **evaluate/**: All evaluation and inference code
- **slurm/**: HPC-specific job submission scripts

### `/logs`
- Training logs from SLURM jobs
- Timestamped for tracking experiments

### `/visualizations`
- Generated plots and figures
- Separate from code for clarity

### `/notebooks`
- Jupyter notebooks for exploration
- Data preprocessing workflow

### `/docs`
- Technical documentation
- Results analysis
- Project summaries

## ðŸš€ Usage Patterns

### Training
```bash
cd scripts/train
python train__model_3.py
```

### Evaluation
```bash
cd scripts/evaluate
python evaluate_model3.py
```

### Interactive Use
```bash
python scripts/evaluate/interactive_translator.py
```

### Documentation
```bash
cat docs/FINAL_RESULTS.md
```

## âœ… Benefits of This Structure

- âœ… **Professional**: Industry-standard organization
- âœ… **Maintainable**: Easy to find and modify files
- âœ… **Scalable**: Simple to add Model 4, Model 5, etc.
- âœ… **Clear**: Anyone can understand the layout
- âœ… **Git-friendly**: Logical .gitignore boundaries
- âœ… **Reproducible**: Clear separation of artifacts

## ðŸ”„ Migration Guide

Files were reorganized from flat structure to hierarchical:

- Training scripts: `./` â†’ `scripts/train/`
- Evaluation scripts: `./` â†’ `scripts/evaluate/`
- Model checkpoints: `./` â†’ `models/model*/`
- Documentation: `./` â†’ `docs/`
- Visualizations: `./` â†’ `visualizations/`
- Notebooks: `./` â†’ `notebooks/`

Symlinks maintain backward compatibility for model files.
